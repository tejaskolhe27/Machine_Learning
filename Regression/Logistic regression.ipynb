{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c241f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed042bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "brupt = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc48540",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = brupt.drop(\"Bankrupt?\",axis = 1)\n",
    "y= brupt['Bankrupt?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07419484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bankrupt?\n",
      "0    96.77372\n",
      "1     3.22628\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b00ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=23,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6367f4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bankrupt?\n",
      "0    96.773563\n",
      "1     3.226437\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a248a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bankrupt?\n",
      "0    96.774194\n",
      "1     3.225806\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbf87b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr =  LogisticRegression()\n",
    "model = lr.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8087205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.18768328445748\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09d9f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.238169688940668\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "print(log_loss(y_test,y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e84797",
   "metadata": {},
   "source": [
    "### KFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22208bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d366fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=23)\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef37d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.961871453990357"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Default scoring=acc score\n",
    "results=cross_val_score(lr,X,y,cv=kfold)\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae091cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#loG LOSS\n",
    "results=cross_val_score(lr,X,y,cv=kfold,scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ac924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18365244634468467"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587a990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71453ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty={'penalty':['l1', 'l2', 'elasticnet', None],\n",
    "         'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c736899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51fe8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv=GridSearchCV(lr,param_grid=penalty,cv=kfold,scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ad3cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 2838, in log_loss\n",
      "    y_pred = check_array(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.47338e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.40905e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.53029e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.48642e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.35897e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 2838, in log_loss\n",
      "    y_pred = check_array(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 2838, in log_loss\n",
      "    y_pred = check_array(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.30594e-38): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.08127e-37): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.07734e-37): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.98939e-37): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.65838e-38): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "55 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1228, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "                                                ^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [        nan -0.10880466         nan         nan         nan -0.17994155\n",
      " -0.18365245 -0.18606408         nan -0.18364396 -0.18001486 -0.17994915\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.18364064         nan         nan -0.18364265 -0.18001954 -0.17994754]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
       "                                    'newton-cholesky', 'sag', 'saga']},\n",
       "             scoring='neg_log_loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2be80b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f28f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10880466175944466\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0638e276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.196475</td>\n",
       "      <td>1.862975</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>-0.123829</td>\n",
       "      <td>-0.113473</td>\n",
       "      <td>-0.111845</td>\n",
       "      <td>-0.092842</td>\n",
       "      <td>-0.102035</td>\n",
       "      <td>-0.108805</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'newton-cg'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'newton-cholesky'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'sag'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.958584</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>-0.181467</td>\n",
       "      <td>-0.173722</td>\n",
       "      <td>-0.167996</td>\n",
       "      <td>-0.187428</td>\n",
       "      <td>-0.189095</td>\n",
       "      <td>-0.179942</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.121985</td>\n",
       "      <td>0.023741</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>-0.194530</td>\n",
       "      <td>-0.177288</td>\n",
       "      <td>-0.172928</td>\n",
       "      <td>-0.186079</td>\n",
       "      <td>-0.187436</td>\n",
       "      <td>-0.183652</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.479397</td>\n",
       "      <td>0.042460</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>-0.197120</td>\n",
       "      <td>-0.177986</td>\n",
       "      <td>-0.182096</td>\n",
       "      <td>-0.185392</td>\n",
       "      <td>-0.187726</td>\n",
       "      <td>-0.186064</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.942868</td>\n",
       "      <td>2.592880</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>-0.198644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.192239</td>\n",
       "      <td>-0.185446</td>\n",
       "      <td>-0.187725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.013355</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'newton-cholesky'}</td>\n",
       "      <td>-0.194531</td>\n",
       "      <td>-0.177288</td>\n",
       "      <td>-0.172928</td>\n",
       "      <td>-0.186037</td>\n",
       "      <td>-0.187436</td>\n",
       "      <td>-0.183644</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.740716</td>\n",
       "      <td>0.089448</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>-0.182404</td>\n",
       "      <td>-0.173651</td>\n",
       "      <td>-0.168111</td>\n",
       "      <td>-0.187313</td>\n",
       "      <td>-0.188596</td>\n",
       "      <td>-0.180015</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.715544</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>-0.181472</td>\n",
       "      <td>-0.173724</td>\n",
       "      <td>-0.168007</td>\n",
       "      <td>-0.187446</td>\n",
       "      <td>-0.189097</td>\n",
       "      <td>-0.179949</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'lbfgs'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'liblinear'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'newton-cg'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'newton-ch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'sag'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'saga'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.100579</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'penalty': None, 'solver': 'lbfgs'}</td>\n",
       "      <td>-0.194533</td>\n",
       "      <td>-0.177288</td>\n",
       "      <td>-0.172928</td>\n",
       "      <td>-0.186018</td>\n",
       "      <td>-0.187436</td>\n",
       "      <td>-0.183641</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'penalty': None, 'solver': 'liblinear'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.051602</td>\n",
       "      <td>3.221983</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'penalty': None, 'solver': 'newton-cg'}</td>\n",
       "      <td>-0.225568</td>\n",
       "      <td>-0.185154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.187724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.104270</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'penalty': None, 'solver': 'newton-cholesky'}</td>\n",
       "      <td>-0.194532</td>\n",
       "      <td>-0.177288</td>\n",
       "      <td>-0.172928</td>\n",
       "      <td>-0.186029</td>\n",
       "      <td>-0.187436</td>\n",
       "      <td>-0.183643</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.821516</td>\n",
       "      <td>0.089348</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>None</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'penalty': None, 'solver': 'sag'}</td>\n",
       "      <td>-0.182380</td>\n",
       "      <td>-0.173651</td>\n",
       "      <td>-0.168123</td>\n",
       "      <td>-0.187341</td>\n",
       "      <td>-0.188603</td>\n",
       "      <td>-0.180020</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.783318</td>\n",
       "      <td>0.076163</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'penalty': None, 'solver': 'saga'}</td>\n",
       "      <td>-0.181488</td>\n",
       "      <td>-0.173724</td>\n",
       "      <td>-0.168007</td>\n",
       "      <td>-0.187420</td>\n",
       "      <td>-0.189098</td>\n",
       "      <td>-0.179948</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.004352      0.000578         0.000000        0.000000   \n",
       "1        2.196475      1.862975         0.005457        0.000445   \n",
       "2        0.002192      0.000166         0.000000        0.000000   \n",
       "3        0.002017      0.000112         0.000000        0.000000   \n",
       "4        0.001986      0.000064         0.000000        0.000000   \n",
       "5        0.958584      0.034371         0.005027        0.000152   \n",
       "6        0.121985      0.023741         0.007453        0.000664   \n",
       "7        0.479397      0.042460         0.005744        0.000250   \n",
       "8        1.942868      2.592880         0.007124        0.001137   \n",
       "9        0.112332      0.013355         0.006837        0.000777   \n",
       "10       0.740716      0.089448         0.005661        0.000456   \n",
       "11       0.715544      0.012109         0.005288        0.000276   \n",
       "12       0.002233      0.000306         0.000000        0.000000   \n",
       "13       0.002213      0.000342         0.000000        0.000000   \n",
       "14       0.001900      0.000029         0.000000        0.000000   \n",
       "15       0.001938      0.000038         0.000000        0.000000   \n",
       "16       0.002057      0.000275         0.000000        0.000000   \n",
       "17       0.001901      0.000016         0.000000        0.000000   \n",
       "18       0.100579      0.002022         0.006403        0.000524   \n",
       "19       0.009669      0.000445         0.000000        0.000000   \n",
       "20       3.051602      3.221983         0.005833        0.000635   \n",
       "21       0.104270      0.005667         0.006509        0.000505   \n",
       "22       0.821516      0.089348         0.006133        0.000277   \n",
       "23       0.783318      0.076163         0.005622        0.000408   \n",
       "\n",
       "   param_penalty     param_solver  \\\n",
       "0             l1            lbfgs   \n",
       "1             l1        liblinear   \n",
       "2             l1        newton-cg   \n",
       "3             l1  newton-cholesky   \n",
       "4             l1              sag   \n",
       "5             l1             saga   \n",
       "6             l2            lbfgs   \n",
       "7             l2        liblinear   \n",
       "8             l2        newton-cg   \n",
       "9             l2  newton-cholesky   \n",
       "10            l2              sag   \n",
       "11            l2             saga   \n",
       "12    elasticnet            lbfgs   \n",
       "13    elasticnet        liblinear   \n",
       "14    elasticnet        newton-cg   \n",
       "15    elasticnet  newton-cholesky   \n",
       "16    elasticnet              sag   \n",
       "17    elasticnet             saga   \n",
       "18          None            lbfgs   \n",
       "19          None        liblinear   \n",
       "20          None        newton-cg   \n",
       "21          None  newton-cholesky   \n",
       "22          None              sag   \n",
       "23          None             saga   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0                {'penalty': 'l1', 'solver': 'lbfgs'}                NaN   \n",
       "1            {'penalty': 'l1', 'solver': 'liblinear'}          -0.123829   \n",
       "2            {'penalty': 'l1', 'solver': 'newton-cg'}                NaN   \n",
       "3      {'penalty': 'l1', 'solver': 'newton-cholesky'}                NaN   \n",
       "4                  {'penalty': 'l1', 'solver': 'sag'}                NaN   \n",
       "5                 {'penalty': 'l1', 'solver': 'saga'}          -0.181467   \n",
       "6                {'penalty': 'l2', 'solver': 'lbfgs'}          -0.194530   \n",
       "7            {'penalty': 'l2', 'solver': 'liblinear'}          -0.197120   \n",
       "8            {'penalty': 'l2', 'solver': 'newton-cg'}          -0.198644   \n",
       "9      {'penalty': 'l2', 'solver': 'newton-cholesky'}          -0.194531   \n",
       "10                 {'penalty': 'l2', 'solver': 'sag'}          -0.182404   \n",
       "11                {'penalty': 'l2', 'solver': 'saga'}          -0.181472   \n",
       "12       {'penalty': 'elasticnet', 'solver': 'lbfgs'}                NaN   \n",
       "13   {'penalty': 'elasticnet', 'solver': 'liblinear'}                NaN   \n",
       "14   {'penalty': 'elasticnet', 'solver': 'newton-cg'}                NaN   \n",
       "15  {'penalty': 'elasticnet', 'solver': 'newton-ch...                NaN   \n",
       "16         {'penalty': 'elasticnet', 'solver': 'sag'}                NaN   \n",
       "17        {'penalty': 'elasticnet', 'solver': 'saga'}                NaN   \n",
       "18               {'penalty': None, 'solver': 'lbfgs'}          -0.194533   \n",
       "19           {'penalty': None, 'solver': 'liblinear'}                NaN   \n",
       "20           {'penalty': None, 'solver': 'newton-cg'}          -0.225568   \n",
       "21     {'penalty': None, 'solver': 'newton-cholesky'}          -0.194532   \n",
       "22                 {'penalty': None, 'solver': 'sag'}          -0.182380   \n",
       "23                {'penalty': None, 'solver': 'saga'}          -0.181488   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1           -0.113473          -0.111845          -0.092842   \n",
       "2                 NaN                NaN                NaN   \n",
       "3                 NaN                NaN                NaN   \n",
       "4                 NaN                NaN                NaN   \n",
       "5           -0.173722          -0.167996          -0.187428   \n",
       "6           -0.177288          -0.172928          -0.186079   \n",
       "7           -0.177986          -0.182096          -0.185392   \n",
       "8                 NaN          -0.192239          -0.185446   \n",
       "9           -0.177288          -0.172928          -0.186037   \n",
       "10          -0.173651          -0.168111          -0.187313   \n",
       "11          -0.173724          -0.168007          -0.187446   \n",
       "12                NaN                NaN                NaN   \n",
       "13                NaN                NaN                NaN   \n",
       "14                NaN                NaN                NaN   \n",
       "15                NaN                NaN                NaN   \n",
       "16                NaN                NaN                NaN   \n",
       "17                NaN                NaN                NaN   \n",
       "18          -0.177288          -0.172928          -0.186018   \n",
       "19                NaN                NaN                NaN   \n",
       "20          -0.185154                NaN                NaN   \n",
       "21          -0.177288          -0.172928          -0.186029   \n",
       "22          -0.173651          -0.168123          -0.187341   \n",
       "23          -0.173724          -0.168007          -0.187420   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 NaN              NaN             NaN               12  \n",
       "1           -0.102035        -0.108805        0.010558                1  \n",
       "2                 NaN              NaN             NaN               12  \n",
       "3                 NaN              NaN             NaN               12  \n",
       "4                 NaN              NaN             NaN               12  \n",
       "5           -0.189095        -0.179942        0.008044                2  \n",
       "6           -0.187436        -0.183652        0.007669               10  \n",
       "7           -0.187726        -0.186064        0.006426               11  \n",
       "8           -0.187725              NaN             NaN               12  \n",
       "9           -0.187436        -0.183644        0.007666                9  \n",
       "10          -0.188596        -0.180015        0.007935                5  \n",
       "11          -0.189097        -0.179949        0.008045                4  \n",
       "12                NaN              NaN             NaN               12  \n",
       "13                NaN              NaN             NaN               12  \n",
       "14                NaN              NaN             NaN               12  \n",
       "15                NaN              NaN             NaN               12  \n",
       "16                NaN              NaN             NaN               12  \n",
       "17                NaN              NaN             NaN               12  \n",
       "18          -0.187436        -0.183641        0.007666                7  \n",
       "19                NaN              NaN             NaN               12  \n",
       "20          -0.187724              NaN             NaN               12  \n",
       "21          -0.187436        -0.183643        0.007666                8  \n",
       "22          -0.188603        -0.180020        0.007936                6  \n",
       "23          -0.189098        -0.179948        0.008041                3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95de9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
