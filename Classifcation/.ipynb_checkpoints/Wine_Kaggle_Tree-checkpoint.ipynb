{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d192bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e29110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.073</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>30.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.079</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99444</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "Id                                                                            \n",
       "0             8.0              0.50         0.39             2.2      0.073   \n",
       "1             9.3              0.30         0.73             2.3      0.092   \n",
       "2             7.1              0.51         0.03             2.1      0.059   \n",
       "3             8.1              0.87         0.22             2.6      0.084   \n",
       "4             8.5              0.36         0.30             2.3      0.079   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "Id                                                                        \n",
       "0                  30.0                  39.0  0.99572  3.33       0.77   \n",
       "1                  30.0                  67.0  0.99854  3.32       0.67   \n",
       "2                   3.0                  12.0  0.99660  3.52       0.73   \n",
       "3                  11.0                  65.0  0.99730  3.20       0.53   \n",
       "4                  10.0                  45.0  0.99444  3.20       1.36   \n",
       "\n",
       "    alcohol  quality  \n",
       "Id                    \n",
       "0      12.1        6  \n",
       "1      12.8        6  \n",
       "2      11.3        7  \n",
       "3       9.8        5  \n",
       "4       9.5        6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine=pd.read_csv('Wine_train.csv',index_col=0)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228ba9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wine.drop('quality',axis=1)\n",
    "y=wine['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64bb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=23,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c62fa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(max_depth=4, random_state=23),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, 6, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 10, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(max_depth=4, random_state=23),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, 6, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 10, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, random_state=23)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, random_state=23)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(max_depth=4, random_state=23),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, None],\n",
       "                         'min_samples_leaf': [1, 3, 5, 7, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='neg_log_loss')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=23)\n",
    "params={'max_depth':[2,3,4,5,6,None],\n",
    "       'min_samples_split':[2,5,6,7,8,9,10],\n",
    "       'min_samples_leaf':[1,3,5,7,10,15]}\n",
    "gcv=GridSearchCV(dtc,param_grid=params,cv=kfold,scoring='neg_log_loss')\n",
    "gcv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0acb827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter : {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "best score : -1.0821447133478768\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameter :\",gcv.best_params_)\n",
    "print(\"best score :\",gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb6dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0585de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp=pd.DataFrame({'variable':best_model.feature_names_in_,\n",
    "                    'importance':best_model.feature_importances_})\n",
    "df_imp=df_imp[df_imp['importance']>0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7610ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sulphates</td>\n",
       "      <td>0.336273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>0.663727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable  importance\n",
       "9   sulphates    0.336273\n",
       "10    alcohol    0.663727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7496a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imp=df_imp.sort_values(by='importance')\n",
    "plt.barh(df_imp['variable'],df_imp['importance'])\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dbcec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.077</td>\n",
       "      <td>31.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99748</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99774</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.056</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.044</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99356</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.48</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "Id                                                                              \n",
       "2056            7.2             0.510         0.01             2.0      0.077   \n",
       "2057            7.2             0.755         0.15             2.0      0.102   \n",
       "2058            8.4             0.460         0.40             2.0      0.065   \n",
       "2059            8.0             0.470         0.40             1.8      0.056   \n",
       "2060            6.5             0.340         0.32             2.1      0.044   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "Id                                                                          \n",
       "2056                 31.0                  54.0  0.99748  3.39       0.59   \n",
       "2057                 14.0                  35.0  0.99586  3.33       0.68   \n",
       "2058                 21.0                  50.0  0.99774  3.08       0.65   \n",
       "2059                 14.0                  25.0  0.99480  3.30       0.65   \n",
       "2060                  8.0                  94.0  0.99356  3.23       0.48   \n",
       "\n",
       "      alcohol  \n",
       "Id             \n",
       "2056      9.8  \n",
       "2057     10.0  \n",
       "2058      9.5  \n",
       "2059     11.7  \n",
       "2060     12.8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_test=pd.read_csv('Wine_test.csv',index_col=0)\n",
    "wine_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "178a2292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 6, ..., 5, 5, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=best_model.predict(wine_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d43dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2056</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2057</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2060</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>3423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>3424</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>3425</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>3426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>3427</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  quality\n",
       "0     2056        5\n",
       "1     2057        6\n",
       "2     2058        6\n",
       "3     2059        6\n",
       "4     2060        6\n",
       "...    ...      ...\n",
       "1367  3423        6\n",
       "1368  3424        6\n",
       "1369  3425        5\n",
       "1370  3426        5\n",
       "1371  3427        6\n",
       "\n",
       "[1372 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({'Id':wine_test.index,'quality':y_pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91294c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"Submit_Wine.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccd1e7",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db6dcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf348818",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e176c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'multi_class':['multinomial','OVR'],'penalty':['l1', 'l2', 'elasticnet', None],\n",
    "         'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfd035cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "195 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1219, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 92, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1219, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 92, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver newton-cholesky does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "120 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'multi_class' parameter of LogisticRegression must be a str among {'ovr', 'multinomial', 'auto'}. Got 'OVR' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/dai/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan -1.16177628\n",
      " -1.10161568         nan -1.04001894         nan -1.14791364 -1.161324\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -1.0988685          nan -1.04245339         nan -1.14788829 -1.16133018\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;multi_class&#x27;: [&#x27;multinomial&#x27;, &#x27;OVR&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;multi_class&#x27;: [&#x27;multinomial&#x27;, &#x27;OVR&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;neg_log_loss&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'multi_class': ['multinomial', 'OVR'],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
       "                                    'newton-cholesky', 'sag', 'saga']},\n",
       "             scoring='neg_log_loss')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv=GridSearchCV(lr,param_grid=params,cv=kfold,scoring='neg_log_loss')\n",
    "gcv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45f7982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter : {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "best score : -1.040018941540796\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameter :\",gcvsubmission.to_csv(\"Submit_Wine.csv\",index=False).best_params_)\n",
    "print(\"best score :\",gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb7be935",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8b7463a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=best_model.predict(wine_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c70e1518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2056</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2058</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2060</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>3423</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>3424</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>3425</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>3426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>3427</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  quality\n",
       "0     2056        5\n",
       "1     2057        5\n",
       "2     2058        5\n",
       "3     2059        6\n",
       "4     2060        6\n",
       "...    ...      ...\n",
       "1367  3423        5\n",
       "1368  3424        6\n",
       "1369  3425        5\n",
       "1370  3426        5\n",
       "1371  3427        5\n",
       "\n",
       "[1372 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({'Id':wine_test.index,'quality':y_pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13b84a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"Submit_Wine_lr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68bdde",
   "metadata": {},
   "source": [
    "## LR with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a5d3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46652d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "pipe=Pipeline([('SCL',scaler),('LR',lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45890ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'LR__multi_class':['multinomial','OVR'],'LR__penalty':['l1', 'l2', 'elasticnet', None],\n",
    "         'LR__solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "       'SCL':[StandardScaler(),MinMaxScaler()]}\n",
    "kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f622175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
